{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron\n",
    "A feed forward neural network with multiple layers and each layer having dense connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: MNIST Digit Classification\n",
    "\n",
    "### Model\n",
    "![alt text](images/MLP.png \"Title\")\n",
    "\n",
    "### Layer Diagram\n",
    "![alt text](images/LayerDiag.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Dataset $\\rightarrow$ Building Computational Graph (Model) $\\rightarrow$ Define Loss and Optimizer $\\rightarrow$ Training (Forward$\\rightarrow$Backward$\\rightarrow$Parameter update) $\\rightarrow$ Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9871360/9912422 [02:29<00:00, 78488.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      " 57%|█████▋    | 16384/28881 [00:00<00:00, 115039.40it/s]\u001b[A\n",
      "32768it [00:00, 101059.44it/s]                           \u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 16384/1648877 [00:00<00:23, 69102.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 40960/1648877 [00:00<00:20, 78527.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 98304/1648877 [00:00<00:15, 100131.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 180224/1648877 [00:01<00:11, 128633.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 270336/1648877 [00:01<00:09, 146243.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 335872/1648877 [00:01<00:06, 189953.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 466944/1648877 [00:01<00:04, 255122.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 565248/1648877 [00:02<00:04, 236214.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 729088/1648877 [00:02<00:03, 293532.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 802816/1648877 [00:02<00:02, 353507.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 884736/1648877 [00:03<00:02, 264206.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 950272/1648877 [00:03<00:02, 301571.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 1040384/1648877 [00:03<00:01, 365230.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 1097728/1648877 [00:03<00:01, 334875.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 1146880/1648877 [00:03<00:01, 338939.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 1196032/1648877 [00:03<00:01, 301983.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 1236992/1648877 [00:04<00:01, 294207.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 1277952/1648877 [00:04<00:01, 305540.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 1327104/1648877 [00:04<00:01, 312170.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 1368064/1648877 [00:04<00:00, 306777.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 1409024/1648877 [00:04<00:00, 314936.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 1458176/1648877 [00:04<00:00, 319537.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 1499136/1648877 [00:04<00:00, 311422.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 1531904/1648877 [00:05<00:00, 188700.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1613824/1648877 [00:05<00:00, 234790.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "1654784it [00:05, 301934.74it/s]                             \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "8192it [00:00, 17310.72it/s]            \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "60000\n",
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f23b4455150>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [02:40, 78488.74it/s]                             \n",
      "32768it [00:20, 101059.44it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init as weight_init\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])\n",
    "\n",
    "#Loading the train set file\n",
    "train_dataset = datasets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=preprocess,  \n",
    "                            download=True)\n",
    "#Loading the test set file\n",
    "test_dataset = datasets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=preprocess)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(train_dataset[0][0].size())\n",
    "\n",
    "#Plotting\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(train_dataset[110][0].squeeze(),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining DataLoader\n",
    "- Batching the data\n",
    "- Shuffling the data\n",
    "- Load the data in parallel using multiprocessing workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([100, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([100]) type: torch.LongTensor\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataloader\n",
    "batch_size = 100\n",
    "\n",
    "#loading the train dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "#loading the test dataset\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break\n",
    "\n",
    "#Plotting 10 digits\n",
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i,:,:,:].numpy().reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "input_size = 784\n",
    "hidden_size = 256\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "learning_rate = 0.01\n",
    "momentum_rate = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        #Weight Initialization\n",
    "        for m in self.modules():\n",
    "          if isinstance(m,nn.Linear):\n",
    "            weight_init.xavier_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "net = Net(input_size, hidden_size, num_classes)\n",
    "\n",
    "#Other functions\n",
    "def loss_plot(losses):\n",
    "    max_epochs = len(losses)\n",
    "    times = list(range(1, max_epochs+1))\n",
    "    plt.figure(figsize=(30, 7))\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"cross-entropy loss\")\n",
    "    return plt.plot(times, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD for Optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum_rate)\n",
    "\n",
    "##RMSProp\n",
    "# torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "##Adam\n",
    "# torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "##Adagrad\n",
    "# torch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA  True\n",
      "Epoch [1/25] Loss:1.6566\n",
      "Epoch [2/25] Loss:1.5404\n",
      "Epoch [3/25] Loss:1.5248\n",
      "Epoch [4/25] Loss:1.5154\n",
      "Epoch [5/25] Loss:1.5089\n",
      "Epoch [6/25] Loss:1.5037\n",
      "Epoch [7/25] Loss:1.4994\n",
      "Epoch [8/25] Loss:1.4961\n",
      "Epoch [9/25] Loss:1.4929\n",
      "Epoch [10/25] Loss:1.4904\n",
      "Epoch [11/25] Loss:1.4881\n",
      "Epoch [12/25] Loss:1.4863\n",
      "Epoch [13/25] Loss:1.4846\n",
      "Epoch [14/25] Loss:1.4831\n",
      "Epoch [15/25] Loss:1.4819\n",
      "Epoch [16/25] Loss:1.4807\n",
      "Epoch [17/25] Loss:1.4797\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print('Using CUDA ', use_cuda)\n",
    "\n",
    "#Transfer to GPU device if available\n",
    "net = net.to(device)\n",
    "net\n",
    "\n",
    "# Training\n",
    "epochLoss = []\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total_loss = 0\n",
    "    cntr = 1\n",
    "    # For each batch of images in train set\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.view(-1, 28*28)\n",
    "        labels = labels\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Initialize gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass (this calls the \"forward\" function within Net)\n",
    "        outputs = net(images)\n",
    "        \n",
    "        # Find the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass (Find the gradients of all weights using the loss)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights using the optimizer\n",
    "        # For e.g.: w = w - (delta_w)*lr\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        cntr += 1\n",
    "    \n",
    "    print('Epoch [%d/%d] Loss:%.4f'%(epoch+1, num_epochs, total_loss/cntr) )\n",
    "    epochLoss.append(total_loss/cntr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = loss_plot(epochLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing (Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# For each batch of images in test set\n",
    "with torch.no_grad():\n",
    "  for images, labels in test_loader:\n",
    "\n",
    "      # Get the images\n",
    "      images = images.view(-1, 28*28)\n",
    "\n",
    "      images = images.to(device)\n",
    "\n",
    "      # Find the output by doing a forward pass through the network\n",
    "      outputs = net(images)\n",
    "\n",
    "      # Find the class of each sample by taking a max across the probabilities of each class\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "      # Increment 'total', and 'correct' according to whether the prediction was correct or not\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design Goals\n",
    "- Varying #neurons, #layers\n",
    "- Activation functions\n",
    "- Loss functions\n",
    "- Learning Rates\n",
    "- Optimizers\n",
    "- Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rates\n",
    "![](images/LR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers\n",
    "Source: Visualization of stochastic optimizers by Alec Radford\n",
    "![](http://2.bp.blogspot.com/-q6l20Vs4P_w/VPmIC7sEhnI/AAAAAAAACC4/g3UOUX2r_yA/s400/s25RsOr%2B-%2BImgur.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier Initialization (Glorot et.al JMLR’10)\n",
    "- Scale of initialization is dependent on the number of input and output neurons.\n",
    "- Initial weights are sampled from $\\mathcal{N}(0,var(w))$, where $var(w)=\\frac{2}{n_{in}+n_{out}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "- Dataset and Dataloader\n",
    "- Model definition and interconnections\n",
    "- Loss function\n",
    "- Forward Pass\n",
    "- Backward Pass\n",
    "- Loss function\n",
    "- Parameter update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
